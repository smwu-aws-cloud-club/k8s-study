# 레플리카셋

- 레플리카셋의 목적이란 레플리카 파드 집합의 실행을 항상 안정적으로 유지하는 것
- 명시된 동일 파드 개수에 대한 가용성 보장

## 레플리카셋의 작동 방식

- 셀렉터 → 실행 가능한 파드를 식별하는 방법 명시 → 레플리카셋은 셀렉터를 기준으로 자신의 파드 관리
- 레플리카의 개수 → 유지해야하는 파드 개수
- 파드 템플릿 → 레플리카셋이 새로운 파드를 생성해야 할 경우, 파드 템플릿을 사용하여 생성

## 레플리카셋을 사용하는 시기

- 레플리카셋 → 지정된 수의 pod 레플리카(복제본)이 항상 실행되도록 보장
- 디플로이먼트 → 레플리카셋을 관리 + 파드에 대한 선언적 업데이트 제공(레플리카셋의 상위 개념) → 일반적으로는 디플로이먼트를 사용하는 것을 권장

### 레플리카셋 생성 후 파드 생성

yaml 작성 → 쿠버네티스 클러스터에 kubectl명령어로 적용

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # 케이스에 따라 레플리카를 수정한다.
  replicas: 3
  selector:
    matchLabels:
      tier: frontend #tier:frontend인 파드들을 레플리카셋이 관리
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google_samples/gb-frontend:v3

```

```yaml
kubectl apply -f https://kubernetes.io/examples/controllers/frontend.yaml
kubectl get rs #배포된 레플리카셋 확인
kubectl get pods #레플리카셋으로부터 올라온 파드 정보 확인
```

## 템플릿을 사용하지 않는 파드의 획득

- 단독으로 생성한 파드 셀렉터의 label과 레플리카셋의 label을 다르게 하는 것을 권장
    
    → 레플리카셋은 label을 기준으로 pod를 관리하기 때문에 만약 단독으로 생성한 파드의 label과 레플리카셋으로 생성된 파드의 label이 같다면, 이 두 파드를 레플리카셋이 관리하게 됨
    

## 레플리카셋 매니페스트 작성하기

```yaml
apiVersion: apps/v1
kind: ReplicaSet #레플리카셋으로 파드 관리
metadata:
  name: frontend
  labels:
    app: guestbook
    tier: frontend
spec:
  # 케이스에 따라 레플리카를 수정한다.
  replicas: 3 #동시에 동작하는 pod의 수
  # 레이블 셀렉터. 레플리카셋이 관리할 pod label
  selector:
    matchLabels:
      tier: frontend #tier:frontend인 파드들을 레플리카셋이 관리
  # 파드 템플릿
  template:
    metadata:
      labels:
        tier: frontend
    spec:
      containers:
      - name: php-redis
        image: gcr.io/google_samples/gb-frontend:v3

```

## 레플리카셋 작업

### 레플리카셋과 해당 파드 삭제

- 레플리카셋 및 모든 파드를 삭제 → [`kubectl delete`](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#delete)를 사용

### 레플리카셋만 삭제

- [`kubectl delete`](https://kubernetes.io/docs/reference/generated/kubectl/kubectl-commands#delete)에 `--cascade=orphan` 옵션을 사용하여 연관 파드에 영향을 주지 않고 레플리카셋을 삭제할 수 있음
- 원본 삭제 시 새 레플리카셋을 생성하여 대체

### 레플리카셋에서 파드 격리

- label을 변경하면 레플리카셋에서 파드를 제거할 수 있음 → 이렇게 제거된 파드는 자동으로 교체됨

### 레플리카셋의 스케일링

- `.spec.replicas` 필드를 업데이트 → 스케일 업 or 다운 가능

### 파드 삭제 비용

- [`controller.kubernetes.io/pod-deletion-cost`](https://kubernetes.io/ko/docs/reference/labels-annotations-taints/#pod-deletion-cost) 어노테이션을 이용하여, 레플리카셋을 스케일 다운할 때 어떤 파드부터 먼저 삭제할지에 대한 우선순위를 설정할 수 있음

## 레플리카셋을 Horizontal Pod Autoscaler 대상으로 설정

- 레플리카셋은 HPA에 대해 오토스케일 될 수 있음 → CPU 사용량에 따라 파드 복제되는 오토스케일 레플리카셋 HPA 생성 가능
- 사용 방법

```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: frontend-scaler
spec:
  scaleTargetRef:
    kind: ReplicaSet
    name: frontend
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 50

```

```yaml
kubectl apply -f https://k8s.io/examples/controllers/hpa-rs.yaml #yaml을 k8s cluster에 적용
kubectl autoscale rs frontend --max=10 --min=3 --cpu-percent=50 # 또는 kubectl autoscale 으로 작업 
```

## 레플리카셋의 대안

- 디플로이먼트
    - 레플리카셋 소유 및 업데이트
    - 파드의 선언적인 업데이트
    - 서버 측 롤링 업데이트
- 기본 파드
    - 사용자가 직접 파드 생성 → 장애가 일어나서 파드가 삭제됨 → 교체 X
    - 하지만 레플리카셋을 이용한다면? → 장애가 일어나서 파드가 삭제된다면 자동으로 교체
- 잡
    - 스스로 종료되는 것이 예상되는 Pod는 job이용
- 데몬셋
    - 머신 모니터링, 머신 로깅

# 디플로이먼트

- 파드와 레플리카셋에 대한 선언적 업데이트
- 디플로이먼트 → 상태, 디플로이먼트 컨트롤러 → 선언된 상태로 조정

## 디플로이먼트 유스케이스

- 레플리카셋을 롤아웃 할 디플로이먼트 생성
- 디플로먼트 업데이트하여 파드의 새로운 상태 선언 → 새 레플리카셋 생성 → 디플로이먼트 컨트롤러는 새 레플리카셋으로 이전 레플리카셋을 조정, 업데이트
- 디플로이먼트의 현재 상태가 안정적이지 않다면 이전 버전으로 롤백
- 디플로이먼트 스케일 업
- 이전 레플리카셋 정리

## 디플로이먼트 생성

- 예시 → 3개의 nginx pod 불러오기 위한 레플리카셋

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment # 디플로이먼트 이름
  labels:
    app: nginx
spec:
  replicas: 3 # 3개의 레플리카 파드를 생성하는 레플리카셋
  selector: # 생성된 레플리카셋이 관리할 파드를 인식하는 방법
    matchLabels: # 파드 템플릿에 정의된 label인 app:nginx를 관리
      app: nginx
  template: 
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx # 컨테이너 이름
        image: nginx:1.14.2 # 컨테이너 이미지 이름
        ports:
        - containerPort: 80 # 컨테이너 포트

```

- 사용 방법

```yaml
# 디플로이먼트 생성
kubectl apply -f https://k8s.io/examples/controllers/nginx-deployment.yaml
# 디플로이먼트 생성 확인
kubectl get deployments
# 디플로이먼트로 생성된 레플리카셋 확인
kubectl get rs
# 파드 확인
kubectl get pods --show-labels
```

## 디플로이먼트 업데이트

- 디플로이먼트의 파드 템플릿(`.spce.template`)변경 (템플릿 레이블 또는 컨테이너 이미지 업데이트) → 디플로이먼트의 롤아웃 트리거 → 디플로이먼트 업데이트
- 업데이트 방법
    
    ```yaml
    # nginx image를 1.14.2 -> 1.16.1로 업데이트
    kubectl set image deployment.v1.apps/nginx-deployment nginx=nginx:1.16.1
    
    # 또는 디플로이먼트 업데이트
    kubectl edit deployment/nginx-deployment
    
    # 롤아웃 상태 확인
    kubectl rollout status deployment/nginx-deployment
    ```
    
- 롤오버
    - 디플로이먼트 업데이트 → 업데이트 이전에 구동되던 레플리카 죽이면서 업데이트된 디플로이먼트 기반으로 레플리카 생성

## 디플로이먼트 롤백

- 디플로이먼트가 지속적인 충돌로 안정적이지 않은 경우 → 기본적으로 모든 디플로이먼트의 롤아웃 기록은 시스템에 남아있어 언제든지 롤백 가능
- 롤아웃 고착 상태
    
    ```bash
    # 디플로이먼트 업데이트 하는 동안 오류가 생긴 경우(ex/디플로이먼트 업데이트 중 이미지 이름 잘못 입력)
    # 롤아웃이 고착됨
    kubectl rollout status deployment/nginx-deployment
    ```
    
- 디플로이먼트를 이전 수정 버전으로 롤백하는 방법
    
    ```bash
    # 이전 버전으로 롤백
    kubectl rollout undo deployment/nginx-deployment
    # 특정 수정 버전으로 롤백 -> 버전을 명시해 주면 됨
    kubectl rollout undo deployment/nginx-deployment --to-revision=2
    # 롤백 성공 후 디플로이먼트가 예상되로 실행되는지 확인
    kubectl get deployment nginx-deployment
    
    ```
    

## 디플로이먼트 스케일링

```bash
# 이 명령어를 이용하면 디플로이먼트의 스케일 업, 스케일 다운 가능
kubectl scale deployment/nginx-deployment --replicas=10
```

### 비례적 스케일링

- 디플로이먼트 롤링업데이트는 여러 버전의 애플리케이션을 동시에 실행할 수 있도록 지원함
- 

## 디플로이먼트 롤아웃 일시 중지와 재개

## 디플로이먼트 상태

- 디플로이먼트는 라이프사이클 동안 진행 중, 완료, 진행 실패 등 다양한 상태로 전환됨

### 디플로이먼트 완료

- 디플로이먼트과 관련된 모든 레플리카가 지정된 최신 버전으로 업데이트 되었을 때
- 디플로이먼트와 관련한 모든 레플리카를 사용할 수 있을 때
- 디플로이먼트에 대해 이전 복제본이 실행되고 있지 않을 때  → 쿠버네티스는 디플로이먼트를 완료로 표시
- 디플로이먼트 완료를 확인하는 방법

```bash
# kubectl rollout status 를 사용해서 디플로이먼트가 완료되었는지 확인
kubectl rollout status deployment/nginx-deployment
```

### 디플로이먼트 실패

- 디플로이먼트를 새 레플리카셋이 완료되지 않은 상태에서 배포를 시도하면 고착될 수 있음
    - 할당량 부족, readiness probe의 실패, 이미지 풀 에러, 권한 부족, 범위 제한, 애플리케이션 런타임의 잘못된 구성

### 실패한 디플로이먼트에서의 운영

- 완료된 디플로이먼트에 적용되는 모든 행동은 실패한 디플로이먼트에도 적용

## 정책 초기화

- 디플로이먼트의 `.spec.revisionHistoryLimit` 필드를 설정해서 디플로이먼트에서 유지해야 하는 이전 레플리카셋의 수를 명시할 수 있음

## 카나리 디플로이먼트

- 디플로이먼트를 이용해서 일부 사용자 또는 서버에 릴리스를 롤아웃 하기 위해 카나리 패턴에 따라 각 릴리스 마다 한개씩 여러 디플로이먼트 생성 가능

## 디플로이먼트 사양 작성

- 파드 템플릿
    - `.spec.template` 과 `.spec.selector` 은 `.spec` 에서 필수 필드
    - `.spec.template` 는 파드 템플릿
    - 적절한 레이블, 적절한 재시작 정책을 명시해야 함
- 레플리카
    - `.spec.replicas` → 필요한 파드의 수를 지정하는 선택적 필드. default = 1
    - [HorizontalPodAutoscaler](https://kubernetes.io/ko/docs/tasks/run-application/horizontal-pod-autoscale/)(또는 수평 스케일링을 위한 유사 API)가 디플로이먼트 크기를 관리하고 있다면  `.spec.replicas` 를 설정해서는 안 됨 → 대신, 쿠버네티스 컨트롤 플레인이 `.spec.replicas` 를 자동으로 관리함
- 셀렉터
    - `.spec.selector` 는 디플로이먼트의 대상이 되는 파드에 대해 [레이블 셀렉터](https://kubernetes.io/ko/docs/concepts/overview/working-with-objects/labels/)를 지정하는 필수 필드
    - `.spec.selector` 는 `.spec.template.metadata.labels` 과 일치해야 함 → 그렇지 않으면 거부됨
    - `apps/v1` → `.spec.selector` 와 `.metadata.labels` 이 설정되지 않는다면
        
        →  `.spec.template.metadata.labels` 은 기본 설정되지 않음
        
    - `apps/v1` 에서는 디플로이먼트를 생성한 후에는 `.spec.selector` 이 변경되지 않음
    - 디플로이먼트는 템플릿의 `.spec.template` 와 다르거나 파드의 수가 `.spec.replicas` 를 초과할 경우 셀렉터와 일치하는 레이블을 가진 파드를 종료할 수 있음
    - 파드의 수가 의도한 수량보다 적을 경우 `.spec.template` 에 맞는 새 파드를 띄움
- 전략
    - `.spec.strategy` 는 이전 파드를 새로운 파드로 대체하는 전략을 명시 → 재생성 or 롤링업데이트
- 디플로이먼트 재생성
    - `.spec.strategy.type==Recreate` → 새 파드가 생성되기 전에 죽음
    - `.spec.strategy.type==RollingUpdate` → 새 파드 롤링 업데이트

# 리소스 관리

## 리소스 구성 configuration

- 디플로이먼트, 서비스 같은 리소스 필요 → 리소스 파일을 한 파일에 그룹화하여 관리
- 리소스는 파일에 표시된 순서대로 생성 → 서비스 먼저 지정 후 스케줄러가 디플로이먼트와 같은 컨트롤러에서 생성한 서비스와 관련된 파드를 분산시킬 수 있음
    
    ```bash
    apiVersion: v1
    kind: Service
    metadata:
      name: my-nginx-svc
      labels:
        app: nginx
    spec:
      type: LoadBalancer
      ports:
      - port: 80
      selector:
        app: nginx
    ---
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      name: my-nginx
      labels:
        app: nginx
    spec:
      replicas: 3
      selector:
        matchLabels:
          app: nginx
      template:
        metadata:
          labels:
            app: nginx
        spec:
          containers:
          - name: nginx
            image: nginx:1.14.2
            ports:
            - containerPort: 80
    
    ```
    

### 리소스 생성 명령어

```bash
kubectl apply -f https://k8s.io/examples/application/nginx-app.yaml
```

## kubectl에서의 대량 작업

- 리소스 생성, 리소스 삭제 가능
- 리소스가 많다면 셀렉터를 이용해서 리소스 필터링
    
    ```bash
    kubectl delete deployment,services -l app=nginx
    
    ```
    

## 효과적인 레이블 사용

- 멀티-티어 어플리케이션은 각 티어를 구별해야 함
    
    ```bash
         labels:
            app: guestbook
            tier: backend
            role: master
    ```
    

→ redis의 master-slave의 경우 여러 tier 어플리케이션

## 레이블 업데이트

- `kubectl label` 로 기존 파드 및 기타 리소스의 레이블을 다시 지정
- 모든 nginx 파드에 프론트엔드 티어로 레이블을 지정하는 case
    
    ```bash
    kubectl label pods -l app=nginx tier=fe
    ```
    

## 어플리케이션 스케일링

- 애플리케이션의 로드가 증가하거나 축소되면, `kubectl` 을 사용하여 애플리케이션을 스케일링

```bash
# 레플리카셋의 개수를 3개에서 1개로 스케일링
kubectl scale deployment/my-nginx --replicas=1
deployment.apps/my-nginx scaled
```

## 리소스 인플레이스 업데이트

- 리소스를 중단없이 업데이트 하는 case
- kubectl apply
    - 구성 파일 셋을 소스 제어에서 유지 → 구성하는 리소스에 대한 코드와 함께 버전을 지정하고 유지
- kubectl edit
    - 리소스 get → vim 에서 편집 → 업데이트된 버전으로 리소스 apply
    
    ```bash
    kubectl edit deployment/my-nginx
    ```
    
- kubectl patch
